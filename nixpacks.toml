# Explicitly set provider for faster detection
[providers]
python = "3.12"

[phases.setup]
nixPkgs = ["python312", "ffmpeg"]

[phases.install]
# Use pip cache and install with optimizations
cmds = [
  "mkdir -p /root/.cache/pip",
  "pip install --upgrade pip setuptools wheel",
  # Install heavy packages first to maximize cache benefits
  "pip install --no-deps openai-whisper==20231117 boto3==1.34.0",
  # Install remaining packages
  "pip install -r requirements.txt"
]

# Cache pip packages between builds
[phases.install.cacheDirectories]
paths = ["/root/.cache/pip"]

# Pre-download Whisper model during build (not runtime)
[phases.build]
cmds = [
  "python3 -c 'import whisper; whisper.load_model(\"base\")'"
]

[start]
cmd = "gunicorn --bind 0.0.0.0:$PORT --workers 2 --threads 4 --timeout 600 app:app"
